{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81120c6f",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "This week we are going to take one of the pre-trained models and adjust it so that it learns to detect our objects instead of the stock 90 objects. This will mean the new model has transfered everything it learned about objects and then learned about our specific object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e44cf4",
   "metadata": {},
   "source": [
    "Some of the images we labeled last week may not have had pasta sauce jars in them. In that case, we need to delete those images from our folder before we move to the train/test phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import argparse\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def validate_xmls(source):\n",
    "    source = source.replace('\\\\', '/')\n",
    "\n",
    "    images = [f for f in os.listdir(source)\n",
    "              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(.jpg|.jpeg|.png)$', f)]\n",
    "\n",
    "    num_images = len(images)\n",
    "\n",
    "    for filename in images:\n",
    "        xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "        if not os.path.exists(os.path.join(source, xml_filename)):\n",
    "            print(\"Removing \" + filename + \"...\")\n",
    "            os.remove(os.path.join(source, filename))\n",
    "        \n",
    "validate_xmls('workspace/training_demo/images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ffbd53",
   "metadata": {},
   "source": [
    " We'll use the next script to move some of these into `train` and some into `test` for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a27747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import argparse\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def iterate_dir(source, dest, ratio, copy_xml):\n",
    "    source = source.replace('\\\\', '/')\n",
    "    dest = dest.replace('\\\\', '/')\n",
    "    train_dir = os.path.join(dest, 'train')\n",
    "    test_dir = os.path.join(dest, 'test')\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    else:\n",
    "        for f in os.listdir(train_dir):\n",
    "            os.remove(os.path.join(train_dir, f))\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "    else:\n",
    "        for f in os.listdir(test_dir):\n",
    "            os.remove(os.path.join(test_dir, f))\n",
    "\n",
    "    images = [f for f in os.listdir(source)\n",
    "              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(.jpg|.jpeg|.png)$', f)]\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_test_images = math.ceil(ratio*num_images)\n",
    "\n",
    "    for i in range(num_test_images):\n",
    "        idx = random.randint(0, len(images)-1)\n",
    "        filename = images[idx]\n",
    "        copyfile(os.path.join(source, filename),\n",
    "                 os.path.join(test_dir, filename))\n",
    "        if copy_xml:\n",
    "            xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "            copyfile(os.path.join(source, xml_filename),\n",
    "                     os.path.join(test_dir,xml_filename))\n",
    "        images.remove(images[idx])\n",
    "\n",
    "    for filename in images:\n",
    "        copyfile(os.path.join(source, filename),\n",
    "                 os.path.join(train_dir, filename))\n",
    "        if copy_xml:\n",
    "            xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "            copyfile(os.path.join(source, xml_filename),\n",
    "                     os.path.join(train_dir, xml_filename))\n",
    "            \n",
    "iterate_dir('workspace/training_demo/images', 'workspace/training_demo/images', 0.1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8da6f",
   "metadata": {},
   "source": [
    "* Create a new text file in the `training_demo/annotations` folder named `label_map.pbtxt`. Use the Jupyter explorer to open the text file and edit it. It should look like this:\n",
    "\n",
    "```\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'pasta_sauce_jar'\n",
    "}\n",
    "```\n",
    "\n",
    "where the name is the label you used to identify the objects in `labelimg`.\n",
    "\n",
    "When it comes time to do multiple labels, your file will look something like this:\n",
    "\n",
    "```\n",
    "item {\n",
    "  id: 1\n",
    "  name: 'nine'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 2\n",
    "  name: 'ten'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 3\n",
    "  name: 'jack'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef866275",
   "metadata": {},
   "source": [
    "Now we need to convert the XML annotations into tensorflow `*.record` files. This script will do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11712bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "def xml_to_csv(path):\n",
    "    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n",
    "    them in a single Pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    path : str\n",
    "        The path containing the .xml files\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        The produced dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    return label_map_dict[row_label]\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "def generate_labels(labels_path, xml_dir, output_path):\n",
    "    global label_map_dict\n",
    "    \n",
    "    label_map = label_map_util.load_labelmap(labels_path)\n",
    "    label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "    path = os.path.join(xml_dir)\n",
    "    examples = xml_to_csv(xml_dir)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('Successfully created the TFRecord file: {}'.format(output_path))\n",
    "\n",
    "        \n",
    "generate_labels('workspace/training_demo/annotations/label_map.pbtxt',\n",
    "               'workspace/training_demo/images/train',\n",
    "               'workspace/training_demo/annotations/train.record')\n",
    "generate_labels('workspace/training_demo/annotations/label_map.pbtxt',\n",
    "               'workspace/training_demo/images/test',\n",
    "               'workspace/training_demo/annotations/test.record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b43eb",
   "metadata": {},
   "source": [
    "We now need to go get the pre-trained model we will be using as our base model.\n",
    "\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "We'll use the `SSD ResNet50 V1 FPN 640x640` for our first test. We'll download the file - it is a `.tar.gz` file that will require using a utility program to unzip it. We'll get it unzipped and save it in the `pre-trained-models` folder we created last week. We'll use 7zip to extract this file (https://www.7-zip.org/download.html). The folder structure will look like this when we are done:\n",
    "\n",
    "```\n",
    "training_demo/\n",
    "├─ ...\n",
    "├─ pre-trained-models/\n",
    "│  └─ ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/\n",
    "│     ├─ checkpoint/\n",
    "│     ├─ saved_model/\n",
    "│     └─ pipeline.config\n",
    "└─ ...\n",
    "```\n",
    "\n",
    "Now that we have downloaded and extracted our pre-trained model, let’s create a directory for our training job. Under the `training_demo/models` create a new directory named `pastasauce_ssd_resnet50_v1_fpn` and copy the `training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config` file inside the newly created directory. Our training_demo/models directory should now look like this:\n",
    "\n",
    "```\n",
    "training_demo/\n",
    "├─ ...\n",
    "├─ models/\n",
    "│  └─ pastasauce_ssd_resnet50_v1_fpn/\n",
    "│     └─ pipeline.config\n",
    "└─ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16efe1",
   "metadata": {},
   "source": [
    "We update the `pipeline.config` file:\n",
    "\n",
    "We need to update line 3:\n",
    "\n",
    "```\n",
    "    num_classes: 1 # Set this to the number of different label classes\n",
    "```\n",
    "\n",
    "Line 131:\n",
    "```\n",
    "train_config {\n",
    "  batch_size: 8 # Increase/Decrease this value depending on the available memory (Higher values require more memory and vice-versa)\n",
    "```\n",
    "\n",
    "Line 161:\n",
    "```\n",
    "  fine_tune_checkpoint: \"pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\" # Path to checkpoint of pre-trained model\n",
    "```\n",
    "\n",
    "Lines 167-168:\n",
    "```\n",
    "  fine_tune_checkpoint_type: \"detection\" # Set this to \"detection\" since we want to be training the full detection model\n",
    "  use_bfloat16: false # Set this to false if you are not training on a TPU\n",
    "```\n",
    "\n",
    "Lines 171-188\n",
    "```\n",
    "train_input_reader {\n",
    "  label_map_path: \"annotations/label_map.pbtxt\" # Path to label map file\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"annotations/train.record\" # Path to training TFRecord file\n",
    "  }\n",
    "}\n",
    "eval_config {\n",
    "  metrics_set: \"coco_detection_metrics\"\n",
    "  use_moving_averages: false\n",
    "}\n",
    "eval_input_reader {\n",
    "  label_map_path: \"annotations/label_map.pbtxt\" # Path to label map file\n",
    "  shuffle: false\n",
    "  num_epochs: 1\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"annotations/test.record\" # Path to testing TFRecord\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Copy the `internship/models/research/object_detection/model_main_tf2.py` file and paste it straight into your `training_demo` folder.\n",
    "\n",
    "run `python model_main_tf2.py --model_dir=models/pastasauce_ssd_resnet50_v1_fpn --pipeline_config_path=models/pastasauce_ssd_resnet50_v1_fpn/pipeline.config`\n",
    "\n",
    "This last one will run for many hours - we will use the tensorboard monitoring to determine when to quit the training. To quit the training, we'll just close the anaconda prompt window that is running the training. This will freeze the training on its last checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b30a87",
   "metadata": {},
   "source": [
    "## Monitoring training\n",
    "\n",
    "Open a new terminal, activate the virtual environment, navigate to the `training_demo` folder, and run the following command:\n",
    "\n",
    "`tensorboard --logdir=models/pastasauce_ssd_resnet50_v1_fpn`\n",
    "\n",
    "The above command will start a new TensorBoard server, which (by default) listens to port 6006 of your machine. Assuming that everything went well, you should see a print-out similar to the one below (plus/minus some warnings):\n",
    "\n",
    "```...\n",
    "TensorBoard 2.2.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "Once this is done, go to your browser and type http://localhost:6006/ in your address bar, following which you should be presented with a dashboard.\n",
    "\n",
    "We'll watch this training for awhile. We're looking for the loss metrics to stabilize- eventually the change will slow down and reach a final point. At this point the training is done and we'll close the terminal to stop the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174da3dd",
   "metadata": {},
   "source": [
    "## Exporting the Trained Model\n",
    "\n",
    "Copy the `internship/models/research/object_detection/exporter_main_v2.py` script and paste it straight into your `training_demo` folder.\n",
    "\n",
    "From the terminal, go to the `training_demo` folder, run: `python .\\exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\\models\\pastasauce_ssd_resnet50_v1_fpn\\pipeline.config --trained_checkpoint_dir .\\models\\pastasauce_ssd_resnet50_v1_fpn\\ --output_directory .\\exported-models\\pastasaucemodel`\n",
    "\n",
    "This command may take a few minutes to run as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2cf14",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "\n",
    "Our last step is to test this model out on images to see how well it works. We'll need to do a couple of things to import the model and run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "# PATH_TO_SAVED_MODEL = \"workspace\\\\training_demo\\\\pre-trained-models\\\\ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\\\\saved_model\"\n",
    "PATH_TO_SAVED_MODEL = \"workspace\\\\training_demo\\\\exported-models\\\\pastasaucemodel\\\\saved_model\"\n",
    "PATH_TO_LABELS = \"workspace\\\\training_demo\\\\annotations\\\\label_map.pbtxt\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8da896",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = [\"workspace\\\\training_demo\\\\images\\\\009.jpg\",\n",
    "               \"workspace\\\\training_demo\\\\images\\\\032.jpg\",\n",
    "               \"workspace\\\\training_demo\\\\images\\\\074.jpg\",\n",
    "              \"workspace\\\\training_demo\\\\images\\\\validations\\\\ftm-pasta-sauce.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b662701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print('Done')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cc929",
   "metadata": {},
   "source": [
    "# Week 4 Project\n",
    "\n",
    "Your turn! Set up and train your first model with the data you collected and tagged last week. We want everyone to have a functioning model to demonstrate to the group. Good luck! Because of the holiday, we'll next meet in two weeks. Be prepared to show your functioning model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1dd16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
