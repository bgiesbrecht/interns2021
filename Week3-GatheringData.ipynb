{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69db33e6",
   "metadata": {},
   "source": [
    "# Gathering and Labeling Data\n",
    "\n",
    "\n",
    "## Setting up the folder structure\n",
    "\n",
    "We're going to create a bunch of folders that we'll need to keep our images and eventually our model organized. The first piece is to add a `working/training_demo` folder like this:\n",
    "\n",
    "```\n",
    "internship/\n",
    "├─ models/\n",
    "│  ├─ community/\n",
    "│  ├─ official/\n",
    "│  ├─ orbit/\n",
    "│  ├─ research/\n",
    "│  └─ ...\n",
    "└─ workspace/\n",
    "   └─ training_demo/\n",
    "```\n",
    "\n",
    "And within the `training_demo` folder, we need this structure:\n",
    "\n",
    "```\n",
    "training_demo/\n",
    "├─ annotations/\n",
    "├─ exported-models/\n",
    "├─ images/\n",
    "│  ├─ test/\n",
    "│  └─ train/\n",
    "├─ models/\n",
    "└─ pre-trained-models/\n",
    "```\n",
    "\n",
    "\n",
    "* `annotations`: This folder will be used to store the respective TensorFlow `*.record` files, which contain the list of annotations for our dataset images.\n",
    "\n",
    "* `exported-models`: This folder will be used to store exported versions of our trained model(s).\n",
    "\n",
    "* `images`: This folder contains a copy of all the images in our dataset, as well as the respective `*.xml` files produced for each one, once labelImg is used to annotate objects.\n",
    "\n",
    "* `images/train`: This folder contains a copy of all images, and the respective `*.xml files`, which will be used to train our model.\n",
    "\n",
    "* `images/test`: This folder contains a copy of all images, and the respective `*.xml` files, which will be used to test our model.\n",
    "\n",
    "* `models`: This folder will contain a sub-folder for each of training job. Each subfolder will contain the training pipeline configuration file `*.config`, as well as all files generated during the training and evaluation of our model.\n",
    "\n",
    "* `pre-trained-models`: This folder will contain the downloaded pre-trained models, which shall be used as a starting checkpoint for our training jobs.\n",
    "\n",
    "\n",
    "When it comes time to do your final project, you will re-create the `training_demo` folder, but name it something like `lastname_project`. The sub-folders and the process from here on out will be the same.\n",
    "\n",
    "* Open anaconda command, activate the `internship` environment. Navigate to the `workspace/training_demo/images` folder.\n",
    "* Download the chromedriver https://sites.google.com/a/chromium.org/chromedriver/downloads and put the `chromedriver.exe` file in the images folder\n",
    "* Run this command to get the tool we need: `git clone https://github.com/ultralytics/google-images-download`\n",
    "* Run `python google-images-download\\bing_scraper.py --search \"pasta sauce shelf\" --limit 100 --download --chromedriver ./chromedriver.exe --size medium --format jpg` to execute the image retrieval script to get a bunch of images. When you do your final project, you will change the \"pasta sauce jar\" to your topic. The files will download to a sub-folder in `images`.\n",
    "> Note: if you get an error saying that the chromedriver isn't correct, try downloading a different version.\n",
    "* Inspect your images - verify that they look like what you want to identify.\n",
    "* Move all the images to the `models/images` folder.\n",
    "* Run the next cell to rename the files to sequential number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2234074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'workspace/training_demo/images/'\n",
    "counter = 1\n",
    "for f in sorted(os.listdir(path)):\n",
    "    suffix = f.split('.')[-1]\n",
    "    if suffix == 'jpg' or suffix == 'png':\n",
    "        # If you have more than 999 training files, update the :03d to :04d, but this shouldn't be an issue\n",
    "        new = '{:03d}.{}'.format(counter, suffix)\n",
    "        os.rename(path + f, path + new)\n",
    "        counter = int(counter) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208feefc",
   "metadata": {},
   "source": [
    "We now need to run the image labeler to label these images. See the documentation here for instructions on labeling: [Image Labeler](https://github.com/tzutalin/labelImg).\n",
    "\n",
    "* Navigate back to the `training_demo/images` folder (`cd ..`)\n",
    "* Run the image labeler: `labelimg`. This should pop up a new window for labeling images. We'll use the PascalVOC format.\n",
    "* Open the source folder `training_demo/images`. Set the save folder as `training_demo/images` - this will put the image data in the right place for us.\n",
    "\n",
    "We'll go throught the basics for image labeling (documentation here https://github.com/tzutalin/labelImg#usage). There is a tutorial here that covers this https://youtu.be/K_mFnvzyLvc?t=9m13s.\n",
    "\n",
    "We need to label all of the jars of pasta sauce with the label `pasta_sauce_jar`. It is important that we use the same label for all the objects we care about. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83217d0c",
   "metadata": {},
   "source": [
    "We should now have a collection of `.jpg` and `.xml` files in the `images` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf404c3c",
   "metadata": {},
   "source": [
    "# Week 3 Project Work\n",
    "\n",
    "We'll start off labeling a single item for training our models, but we'll eventually want to train a multi-class model that can identify different objects. The project this week is to pick what object you want to detect and get 100-200 images labeled for that object. You can use the Google download trick we did above or you can go get your own images. If you take pictures, be sure to vary the angles and distances from the object. You want a variety of backgrounds, too. Basically, try to capture the object in as many real-world places and angles as you might expect to find when the final model is implemented.\n",
    "\n",
    "It is also possible to capture videos and extract the frames as images. I'd recommend searching for tools to help you do this ([like this site](https://www.raymond.cc/blog/extract-video-frames-to-images-using-vlc-media-player/)). The same applies to videos as still images- capture a variety of angles, distances, and backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594da10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
